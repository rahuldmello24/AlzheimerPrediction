{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yvOwmriUEp3H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Read the Dataset\n",
        "df = pd.read_csv(\"alzheimers_prediction_dataset.csv\")\n",
        "print(\"Loaded dataset with shape:\", df.shape)\n",
        "print(df.head())\n",
        "\n",
        "TARGET_COL = \"Alzheimer’s Diagnosis\"\n",
        "\n",
        "print(\"\\n===== Basic Info =====\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\n===== Value counts of Target =====\")\n",
        "print(df[TARGET_COL].value_counts())\n",
        "\n",
        "print(\"\\n===== Numeric Describe =====\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84dIwBGeE-eR",
        "outputId": "7638ecd1-843d-467c-a719-010bb9049e54"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset with shape: (74283, 25)\n",
            "        Country  Age  Gender  Education Level   BMI Physical Activity Level  \\\n",
            "0         Spain   90    Male                1  33.0                  Medium   \n",
            "1     Argentina   72    Male                7  29.9                  Medium   \n",
            "2  South Africa   86  Female               19  22.9                    High   \n",
            "3         China   53    Male               17  31.2                     Low   \n",
            "4        Sweden   58  Female                3  30.0                    High   \n",
            "\n",
            "  Smoking Status Alcohol Consumption Diabetes Hypertension  ...  \\\n",
            "0          Never        Occasionally       No           No  ...   \n",
            "1         Former               Never       No           No  ...   \n",
            "2        Current        Occasionally       No          Yes  ...   \n",
            "3          Never           Regularly      Yes           No  ...   \n",
            "4         Former               Never      Yes           No  ...   \n",
            "\n",
            "  Dietary Habits Air Pollution Exposure  Employment Status Marital Status  \\\n",
            "0        Healthy                   High            Retired         Single   \n",
            "1        Healthy                 Medium         Unemployed        Widowed   \n",
            "2        Average                 Medium           Employed         Single   \n",
            "3        Healthy                 Medium            Retired         Single   \n",
            "4      Unhealthy                   High           Employed        Married   \n",
            "\n",
            "  Genetic Risk Factor (APOE-ε4 allele) Social Engagement Level Income Level  \\\n",
            "0                                   No                     Low       Medium   \n",
            "1                                   No                    High          Low   \n",
            "2                                   No                     Low       Medium   \n",
            "3                                   No                    High       Medium   \n",
            "4                                   No                     Low       Medium   \n",
            "\n",
            "  Stress Levels Urban vs Rural Living Alzheimer’s Diagnosis  \n",
            "0          High                 Urban                    No  \n",
            "1          High                 Urban                    No  \n",
            "2          High                 Rural                    No  \n",
            "3           Low                 Rural                    No  \n",
            "4          High                 Rural                    No  \n",
            "\n",
            "[5 rows x 25 columns]\n",
            "\n",
            "===== Basic Info =====\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 74283 entries, 0 to 74282\n",
            "Data columns (total 25 columns):\n",
            " #   Column                                Non-Null Count  Dtype  \n",
            "---  ------                                --------------  -----  \n",
            " 0   Country                               74283 non-null  object \n",
            " 1   Age                                   74283 non-null  int64  \n",
            " 2   Gender                                74283 non-null  object \n",
            " 3   Education Level                       74283 non-null  int64  \n",
            " 4   BMI                                   74283 non-null  float64\n",
            " 5   Physical Activity Level               74283 non-null  object \n",
            " 6   Smoking Status                        74283 non-null  object \n",
            " 7   Alcohol Consumption                   74283 non-null  object \n",
            " 8   Diabetes                              74283 non-null  object \n",
            " 9   Hypertension                          74283 non-null  object \n",
            " 10  Cholesterol Level                     74283 non-null  object \n",
            " 11  Family History of Alzheimer’s         74283 non-null  object \n",
            " 12  Cognitive Test Score                  74283 non-null  int64  \n",
            " 13  Depression Level                      74283 non-null  object \n",
            " 14  Sleep Quality                         74283 non-null  object \n",
            " 15  Dietary Habits                        74283 non-null  object \n",
            " 16  Air Pollution Exposure                74283 non-null  object \n",
            " 17  Employment Status                     74283 non-null  object \n",
            " 18  Marital Status                        74283 non-null  object \n",
            " 19  Genetic Risk Factor (APOE-ε4 allele)  74283 non-null  object \n",
            " 20  Social Engagement Level               74283 non-null  object \n",
            " 21  Income Level                          74283 non-null  object \n",
            " 22  Stress Levels                         74283 non-null  object \n",
            " 23  Urban vs Rural Living                 74283 non-null  object \n",
            " 24  Alzheimer’s Diagnosis                 74283 non-null  object \n",
            "dtypes: float64(1), int64(3), object(21)\n",
            "memory usage: 14.2+ MB\n",
            "None\n",
            "\n",
            "===== Value counts of Target =====\n",
            "Alzheimer’s Diagnosis\n",
            "No     43570\n",
            "Yes    30713\n",
            "Name: count, dtype: int64\n",
            "\n",
            "===== Numeric Describe =====\n",
            "                Age  Education Level           BMI  Cognitive Test Score\n",
            "count  74283.000000     74283.000000  74283.000000          74283.000000\n",
            "mean      71.964703         9.487514     26.780639             64.654241\n",
            "std       12.980748         5.757020      4.764679             20.153247\n",
            "min       50.000000         0.000000     18.500000             30.000000\n",
            "25%       61.000000         4.000000     22.700000             47.000000\n",
            "50%       72.000000         9.000000     26.800000             65.000000\n",
            "75%       83.000000        14.000000     30.900000             82.000000\n",
            "max       94.000000        19.000000     35.000000             99.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if \"Country\" in df.columns:\n",
        "    df = df.drop(columns=[\"Country\"], errors=\"ignore\")\n",
        "\n",
        "X = df.drop(columns=[TARGET_COL], errors=\"ignore\")\n",
        "y = df[TARGET_COL]\n",
        "\n",
        "print(\"\\nShapes BEFORE train/test split:\")\n",
        "print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print(\"\\nShapes AFTER train/test split:\")\n",
        "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
        "print(\"X_test: \", X_test.shape,  \"y_test: \", y_test.shape)\n",
        "\n",
        "# Oversample\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_train_res, y_train_res = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "# Reset indices to avoid out-of-bounds errors\n",
        "X_train_res = X_train_res.reset_index(drop=True)\n",
        "y_train_res = y_train_res.reset_index(drop=True)\n",
        "\n",
        "print(\"\\nShapes AFTER Oversampling (train only):\")\n",
        "print(\"X_train_res:\", X_train_res.shape, \"y_train_res:\", y_train_res.shape)"
      ],
      "metadata": {
        "id": "Znik9dmkFDh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83375fef-dd86-45fa-db94-bf0af6481ce5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shapes BEFORE train/test split:\n",
            "X shape: (74283, 23) y shape: (74283,)\n",
            "\n",
            "Shapes AFTER train/test split:\n",
            "X_train: (59426, 23) y_train: (59426,)\n",
            "X_test:  (14857, 23) y_test:  (14857,)\n",
            "\n",
            "Shapes AFTER Oversampling (train only):\n",
            "X_train_res: (69712, 23) y_train_res: (69712,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Numeric & Categorical Processing\n",
        "numeric_cols = [\"Age\", \"Education Level\", \"BMI\", \"Cognitive Test Score\"]\n",
        "categorical_cols = list(set(X_train_res.columns) - set(numeric_cols))\n",
        "for col in numeric_cols:\n",
        "    if col not in X_train_res.columns:\n",
        "        print(f\"Warning: numeric column '{col}' not found in X_train_res.\")\n",
        "\n",
        "# Scale numeric features\n",
        "scaler = StandardScaler()\n",
        "X_train_res[numeric_cols] = scaler.fit_transform(X_train_res[numeric_cols])\n",
        "\n",
        "# Transform test set\n",
        "if set(numeric_cols).issubset(X_test.columns):\n",
        "    X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
        "\n",
        "# One-Hot encode categorical\n",
        "print(\"\\n===== One-Hot Encoding =====\")\n",
        "print(\"Categorical columns:\", categorical_cols)\n",
        "X_train_res = pd.get_dummies(X_train_res, columns=categorical_cols, drop_first=True)\n",
        "X_test = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True)\n",
        "X_test = X_test.reindex(columns=X_train_res.columns, fill_value=0)\n",
        "\n",
        "# Convert target to 0/1\n",
        "y_train_res_bin = (y_train_res == \"Yes\").astype(int)\n",
        "y_test_bin = (y_test == \"Yes\").astype(int)\n",
        "\n",
        "print(\"\\nFinal training data shape:\", X_train_res.shape, y_train_res_bin.shape)\n",
        "print(\"Final testing data shape: \", X_test.shape,  y_test_bin.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4xzGHuuFqdH",
        "outputId": "91b8706a-d79e-4275-99ca-1cb0d9460029"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== One-Hot Encoding =====\n",
            "Categorical columns: ['Smoking Status', 'Hypertension', 'Depression Level', 'Diabetes', 'Air Pollution Exposure', 'Stress Levels', 'Physical Activity Level', 'Urban vs Rural Living', 'Marital Status', 'Gender', 'Genetic Risk Factor (APOE-ε4 allele)', 'Income Level', 'Sleep Quality', 'Family History of Alzheimer’s', 'Social Engagement Level', 'Employment Status', 'Cholesterol Level', 'Alcohol Consumption', 'Dietary Habits']\n",
            "\n",
            "Final training data shape: (69712, 35) (69712,)\n",
            "Final testing data shape:  (14857, 35) (14857,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Convert to float32 & Build Dataset / DataLoader\n",
        "print(\"\\nConverting DataFrames to float32...\")\n",
        "X_train_res = X_train_res.astype(\"float32\")\n",
        "X_test = X_test.astype(\"float32\")\n",
        "print(\"Conversion done.\")\n",
        "\n",
        "class BinaryDataset(Dataset):\n",
        "    \"\"\"Custom PyTorch Dataset for binary classification.\"\"\"\n",
        "    def __init__(self, data_df, labels):\n",
        "        # Convert DataFrame -> torch tensors\n",
        "        self.data = torch.tensor(data_df.values, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels.values, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "print(\"Creating train_dataset...\")\n",
        "train_dataset = BinaryDataset(X_train_res, y_train_res_bin)\n",
        "print(\"Creating test_dataset...\")\n",
        "test_dataset  = BinaryDataset(X_test,      y_test_bin)\n",
        "\n",
        "print(\"Train dataset length:\", len(train_dataset))\n",
        "print(\"Test dataset length:\", len(test_dataset))\n",
        "\n",
        "def manual_iteration_check(ds, n=5):\n",
        "    print(f\"\\nChecking first {n} samples in dataset ...\")\n",
        "    for i in range(n):\n",
        "        features, label = ds[i]\n",
        "        print(f\"Index={i}, features shape={features.shape}, label={label}\")\n",
        "\n",
        "manual_iteration_check(train_dataset, n=5)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39SHQinRF8-3",
        "outputId": "c3425a58-5828-4e0e-e4d3-1b6b631129a4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Converting DataFrames to float32...\n",
            "Conversion done.\n",
            "Creating train_dataset...\n",
            "Creating test_dataset...\n",
            "Train dataset length: 69712\n",
            "Test dataset length: 14857\n",
            "\n",
            "Checking first 5 samples in dataset ...\n",
            "Index=0, features shape=torch.Size([35]), label=0.0\n",
            "Index=1, features shape=torch.Size([35]), label=1.0\n",
            "Index=2, features shape=torch.Size([35]), label=0.0\n",
            "Index=3, features shape=torch.Size([35]), label=1.0\n",
            "Index=4, features shape=torch.Size([35]), label=0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Define a Large MLP with BatchNorm\n",
        "class BigBinaryMLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Larger feed-forward network: 512 -> 256 -> 128 hidden layers,\n",
        "    each followed by BatchNorm + ReLU,\n",
        "    final Sigmoid for binary classification.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 512)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.fc4 = nn.Linear(128, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        x = self.fc4(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BigBinaryMLP(input_size=X_train_res.shape[1]).to(device)\n",
        "print(\"\\nModel Architecture:\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsPXPfhnGBSK",
        "outputId": "d26e9579-f5a7-4a0e-9787-529fa03c7c84"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Architecture:\n",
            "BigBinaryMLP(\n",
            "  (fc1): Linear(in_features=35, out_features=512, bias=True)\n",
            "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu2): ReLU()\n",
            "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (fc4): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Train Function\n",
        "def train_model(model, train_loader, epochs=20, lr=0.001, threshold=0.5):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.BCELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        total_samples = 0\n",
        "        correct = 0\n",
        "\n",
        "        for i, (xb, yb) in enumerate(train_loader):\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            out = model(xb).squeeze()\n",
        "            loss = loss_fn(out, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Accuracy in-batch\n",
        "            preds = (out >= threshold).float()\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total_samples += yb.size(0)\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        acc = correct / total_samples\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f} - Acc: {acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xjkeN4eoGDzo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) Evaluation Function\n",
        "def evaluate_model(model, X_data, y_data, threshold=0.5):\n",
        "    model.eval()\n",
        "    inputs = torch.tensor(X_data.values, dtype=torch.float32).to(device)\n",
        "    labels = torch.tensor(y_data.values, dtype=torch.float32).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs).squeeze()\n",
        "        preds = (outputs >= threshold).float()\n",
        "\n",
        "    # Move back to CPU for scoring\n",
        "    preds_np = preds.cpu().numpy()\n",
        "    labels_np = labels.cpu().numpy()\n",
        "\n",
        "    acc  = accuracy_score(labels_np, preds_np)\n",
        "    prec = precision_score(labels_np, preds_np, zero_division=0)\n",
        "    rec  = recall_score(labels_np, preds_np, zero_division=0)\n",
        "    f1   = f1_score(labels_np, preds_np, zero_division=0)\n",
        "    auc  = roc_auc_score(labels_np, outputs.cpu().numpy())\n",
        "\n",
        "    print(\"\\n--- Evaluation Results ---\")\n",
        "    print(f\"Accuracy:  {acc:.3f}\")\n",
        "    print(f\"Precision: {prec:.3f}\")\n",
        "    print(f\"Recall:    {rec:.3f}\")\n",
        "    print(f\"F1 Score:  {f1:.3f}\")\n",
        "    print(f\"AUC:       {auc:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "1Z1O88XeGGJP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) Training & Evaluation\n",
        "print(\"\\n===== Starting Training with a Large MLP =====\")\n",
        "train_model(model, train_loader, epochs=100, lr=1e-3, threshold=0.5)\n",
        "\n",
        "print(\"\\n===== Evaluating on Test Set =====\")\n",
        "evaluate_model(model, X_test, y_test_bin, threshold=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTsrR7FUGHLv",
        "outputId": "554b8093-6769-422f-804f-6cdf39be0d81"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Starting Training with a Large MLP =====\n",
            "Epoch [1/100] - Loss: 0.5658 - Acc: 0.7136\n",
            "Epoch [2/100] - Loss: 0.5549 - Acc: 0.7199\n",
            "Epoch [3/100] - Loss: 0.5513 - Acc: 0.7224\n",
            "Epoch [4/100] - Loss: 0.5478 - Acc: 0.7228\n",
            "Epoch [5/100] - Loss: 0.5428 - Acc: 0.7255\n",
            "Epoch [6/100] - Loss: 0.5363 - Acc: 0.7287\n",
            "Epoch [7/100] - Loss: 0.5277 - Acc: 0.7344\n",
            "Epoch [8/100] - Loss: 0.5180 - Acc: 0.7413\n",
            "Epoch [9/100] - Loss: 0.5052 - Acc: 0.7502\n",
            "Epoch [10/100] - Loss: 0.4884 - Acc: 0.7610\n",
            "Epoch [11/100] - Loss: 0.4706 - Acc: 0.7722\n",
            "Epoch [12/100] - Loss: 0.4511 - Acc: 0.7837\n",
            "Epoch [13/100] - Loss: 0.4333 - Acc: 0.7961\n",
            "Epoch [14/100] - Loss: 0.4105 - Acc: 0.8100\n",
            "Epoch [15/100] - Loss: 0.3915 - Acc: 0.8211\n",
            "Epoch [16/100] - Loss: 0.3730 - Acc: 0.8313\n",
            "Epoch [17/100] - Loss: 0.3570 - Acc: 0.8399\n",
            "Epoch [18/100] - Loss: 0.3364 - Acc: 0.8513\n",
            "Epoch [19/100] - Loss: 0.3209 - Acc: 0.8582\n",
            "Epoch [20/100] - Loss: 0.3030 - Acc: 0.8686\n",
            "Epoch [21/100] - Loss: 0.2887 - Acc: 0.8742\n",
            "Epoch [22/100] - Loss: 0.2747 - Acc: 0.8834\n",
            "Epoch [23/100] - Loss: 0.2621 - Acc: 0.8876\n",
            "Epoch [24/100] - Loss: 0.2508 - Acc: 0.8955\n",
            "Epoch [25/100] - Loss: 0.2422 - Acc: 0.8984\n",
            "Epoch [26/100] - Loss: 0.2300 - Acc: 0.9036\n",
            "Epoch [27/100] - Loss: 0.2204 - Acc: 0.9080\n",
            "Epoch [28/100] - Loss: 0.2116 - Acc: 0.9124\n",
            "Epoch [29/100] - Loss: 0.2063 - Acc: 0.9158\n",
            "Epoch [30/100] - Loss: 0.1967 - Acc: 0.9191\n",
            "Epoch [31/100] - Loss: 0.1921 - Acc: 0.9212\n",
            "Epoch [32/100] - Loss: 0.1841 - Acc: 0.9250\n",
            "Epoch [33/100] - Loss: 0.1792 - Acc: 0.9280\n",
            "Epoch [34/100] - Loss: 0.1684 - Acc: 0.9323\n",
            "Epoch [35/100] - Loss: 0.1693 - Acc: 0.9319\n",
            "Epoch [36/100] - Loss: 0.1617 - Acc: 0.9356\n",
            "Epoch [37/100] - Loss: 0.1634 - Acc: 0.9345\n",
            "Epoch [38/100] - Loss: 0.1548 - Acc: 0.9378\n",
            "Epoch [39/100] - Loss: 0.1584 - Acc: 0.9361\n",
            "Epoch [40/100] - Loss: 0.1479 - Acc: 0.9422\n",
            "Epoch [41/100] - Loss: 0.1484 - Acc: 0.9411\n",
            "Epoch [42/100] - Loss: 0.1423 - Acc: 0.9446\n",
            "Epoch [43/100] - Loss: 0.1392 - Acc: 0.9456\n",
            "Epoch [44/100] - Loss: 0.1340 - Acc: 0.9474\n",
            "Epoch [45/100] - Loss: 0.1374 - Acc: 0.9466\n",
            "Epoch [46/100] - Loss: 0.1332 - Acc: 0.9485\n",
            "Epoch [47/100] - Loss: 0.1321 - Acc: 0.9487\n",
            "Epoch [48/100] - Loss: 0.1254 - Acc: 0.9502\n",
            "Epoch [49/100] - Loss: 0.1282 - Acc: 0.9507\n",
            "Epoch [50/100] - Loss: 0.1221 - Acc: 0.9532\n",
            "Epoch [51/100] - Loss: 0.1208 - Acc: 0.9531\n",
            "Epoch [52/100] - Loss: 0.1177 - Acc: 0.9542\n",
            "Epoch [53/100] - Loss: 0.1170 - Acc: 0.9545\n",
            "Epoch [54/100] - Loss: 0.1149 - Acc: 0.9560\n",
            "Epoch [55/100] - Loss: 0.1129 - Acc: 0.9569\n",
            "Epoch [56/100] - Loss: 0.1138 - Acc: 0.9561\n",
            "Epoch [57/100] - Loss: 0.1132 - Acc: 0.9565\n",
            "Epoch [58/100] - Loss: 0.1078 - Acc: 0.9595\n",
            "Epoch [59/100] - Loss: 0.1072 - Acc: 0.9588\n",
            "Epoch [60/100] - Loss: 0.1102 - Acc: 0.9570\n",
            "Epoch [61/100] - Loss: 0.1044 - Acc: 0.9600\n",
            "Epoch [62/100] - Loss: 0.1033 - Acc: 0.9608\n",
            "Epoch [63/100] - Loss: 0.1031 - Acc: 0.9607\n",
            "Epoch [64/100] - Loss: 0.1027 - Acc: 0.9603\n",
            "Epoch [65/100] - Loss: 0.1001 - Acc: 0.9619\n",
            "Epoch [66/100] - Loss: 0.0980 - Acc: 0.9629\n",
            "Epoch [67/100] - Loss: 0.0992 - Acc: 0.9627\n",
            "Epoch [68/100] - Loss: 0.0987 - Acc: 0.9622\n",
            "Epoch [69/100] - Loss: 0.0940 - Acc: 0.9644\n",
            "Epoch [70/100] - Loss: 0.0945 - Acc: 0.9640\n",
            "Epoch [71/100] - Loss: 0.0888 - Acc: 0.9666\n",
            "Epoch [72/100] - Loss: 0.0923 - Acc: 0.9653\n",
            "Epoch [73/100] - Loss: 0.0926 - Acc: 0.9649\n",
            "Epoch [74/100] - Loss: 0.0921 - Acc: 0.9652\n",
            "Epoch [75/100] - Loss: 0.0896 - Acc: 0.9661\n",
            "Epoch [76/100] - Loss: 0.0873 - Acc: 0.9668\n",
            "Epoch [77/100] - Loss: 0.0855 - Acc: 0.9680\n",
            "Epoch [78/100] - Loss: 0.0861 - Acc: 0.9676\n",
            "Epoch [79/100] - Loss: 0.0845 - Acc: 0.9677\n",
            "Epoch [80/100] - Loss: 0.0829 - Acc: 0.9692\n",
            "Epoch [81/100] - Loss: 0.0853 - Acc: 0.9679\n",
            "Epoch [82/100] - Loss: 0.0841 - Acc: 0.9683\n",
            "Epoch [83/100] - Loss: 0.0839 - Acc: 0.9685\n",
            "Epoch [84/100] - Loss: 0.0818 - Acc: 0.9700\n",
            "Epoch [85/100] - Loss: 0.0832 - Acc: 0.9686\n",
            "Epoch [86/100] - Loss: 0.0823 - Acc: 0.9695\n",
            "Epoch [87/100] - Loss: 0.0819 - Acc: 0.9696\n",
            "Epoch [88/100] - Loss: 0.0806 - Acc: 0.9705\n",
            "Epoch [89/100] - Loss: 0.0781 - Acc: 0.9710\n",
            "Epoch [90/100] - Loss: 0.0768 - Acc: 0.9709\n",
            "Epoch [91/100] - Loss: 0.0773 - Acc: 0.9712\n",
            "Epoch [92/100] - Loss: 0.0754 - Acc: 0.9717\n",
            "Epoch [93/100] - Loss: 0.0774 - Acc: 0.9709\n",
            "Epoch [94/100] - Loss: 0.0745 - Acc: 0.9727\n",
            "Epoch [95/100] - Loss: 0.0727 - Acc: 0.9736\n",
            "Epoch [96/100] - Loss: 0.0744 - Acc: 0.9715\n",
            "Epoch [97/100] - Loss: 0.0727 - Acc: 0.9735\n",
            "Epoch [98/100] - Loss: 0.0742 - Acc: 0.9720\n",
            "Epoch [99/100] - Loss: 0.0708 - Acc: 0.9731\n",
            "Epoch [100/100] - Loss: 0.0746 - Acc: 0.9721\n",
            "\n",
            "===== Evaluating on Test Set =====\n",
            "\n",
            "--- Evaluation Results ---\n",
            "Accuracy:  0.656\n",
            "Precision: 0.583\n",
            "Recall:    0.587\n",
            "F1 Score:  0.585\n",
            "AUC:       0.711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CKlAXxvDGIBw"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}