{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "313ed74b",
   "metadata": {
    "id": "313ed74b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c61a6e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c61a6e8",
    "outputId": "c5e5ddb2-410e-4d10-d2ff-29de889be08e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded partial dataset with shape: (74283, 25)\n",
      "        Country  Age  Gender  Education Level   BMI Physical Activity Level  \\\n",
      "0         Spain   90    Male                1  33.0                  Medium   \n",
      "1     Argentina   72    Male                7  29.9                  Medium   \n",
      "2  South Africa   86  Female               19  22.9                    High   \n",
      "3         China   53    Male               17  31.2                     Low   \n",
      "4        Sweden   58  Female                3  30.0                    High   \n",
      "\n",
      "  Smoking Status Alcohol Consumption Diabetes Hypertension  ...  \\\n",
      "0          Never        Occasionally       No           No  ...   \n",
      "1         Former               Never       No           No  ...   \n",
      "2        Current        Occasionally       No          Yes  ...   \n",
      "3          Never           Regularly      Yes           No  ...   \n",
      "4         Former               Never      Yes           No  ...   \n",
      "\n",
      "  Dietary Habits Air Pollution Exposure  Employment Status Marital Status  \\\n",
      "0        Healthy                   High            Retired         Single   \n",
      "1        Healthy                 Medium         Unemployed        Widowed   \n",
      "2        Average                 Medium           Employed         Single   \n",
      "3        Healthy                 Medium            Retired         Single   \n",
      "4      Unhealthy                   High           Employed        Married   \n",
      "\n",
      "  Genetic Risk Factor (APOE-ε4 allele) Social Engagement Level Income Level  \\\n",
      "0                                   No                     Low       Medium   \n",
      "1                                   No                    High          Low   \n",
      "2                                   No                     Low       Medium   \n",
      "3                                   No                    High       Medium   \n",
      "4                                   No                     Low       Medium   \n",
      "\n",
      "  Stress Levels Urban vs Rural Living Alzheimer’s Diagnosis  \n",
      "0          High                 Urban                    No  \n",
      "1          High                 Urban                    No  \n",
      "2          High                 Rural                    No  \n",
      "3           Low                 Rural                    No  \n",
      "4          High                 Rural                    No  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/alzheimers_prediction_dataset.csv\")\n",
    "print(\"Loaded partial dataset with shape:\", df.shape)\n",
    "print(df.head())\n",
    "TARGET_COL = \"Alzheimer’s Diagnosis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4b37e0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4b37e0a",
    "outputId": "4795ff4a-d5a5-4ab9-cf69-14ee471aba80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Basic Info =====\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74283 entries, 0 to 74282\n",
      "Data columns (total 25 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   Country                               74283 non-null  object \n",
      " 1   Age                                   74283 non-null  int64  \n",
      " 2   Gender                                74283 non-null  object \n",
      " 3   Education Level                       74283 non-null  int64  \n",
      " 4   BMI                                   74283 non-null  float64\n",
      " 5   Physical Activity Level               74283 non-null  object \n",
      " 6   Smoking Status                        74283 non-null  object \n",
      " 7   Alcohol Consumption                   74283 non-null  object \n",
      " 8   Diabetes                              74283 non-null  object \n",
      " 9   Hypertension                          74283 non-null  object \n",
      " 10  Cholesterol Level                     74283 non-null  object \n",
      " 11  Family History of Alzheimer’s         74283 non-null  object \n",
      " 12  Cognitive Test Score                  74283 non-null  int64  \n",
      " 13  Depression Level                      74283 non-null  object \n",
      " 14  Sleep Quality                         74283 non-null  object \n",
      " 15  Dietary Habits                        74283 non-null  object \n",
      " 16  Air Pollution Exposure                74283 non-null  object \n",
      " 17  Employment Status                     74283 non-null  object \n",
      " 18  Marital Status                        74283 non-null  object \n",
      " 19  Genetic Risk Factor (APOE-ε4 allele)  74283 non-null  object \n",
      " 20  Social Engagement Level               74283 non-null  object \n",
      " 21  Income Level                          74283 non-null  object \n",
      " 22  Stress Levels                         74283 non-null  object \n",
      " 23  Urban vs Rural Living                 74283 non-null  object \n",
      " 24  Alzheimer’s Diagnosis                 74283 non-null  object \n",
      "dtypes: float64(1), int64(3), object(21)\n",
      "memory usage: 14.2+ MB\n",
      "None\n",
      "\n",
      "===== Value counts of Target =====\n",
      "Alzheimer’s Diagnosis\n",
      "No     43570\n",
      "Yes    30713\n",
      "Name: count, dtype: int64\n",
      "\n",
      "===== Numeric Describe =====\n",
      "                Age  Education Level           BMI  Cognitive Test Score\n",
      "count  74283.000000     74283.000000  74283.000000          74283.000000\n",
      "mean      71.964703         9.487514     26.780639             64.654241\n",
      "std       12.980748         5.757020      4.764679             20.153247\n",
      "min       50.000000         0.000000     18.500000             30.000000\n",
      "25%       61.000000         4.000000     22.700000             47.000000\n",
      "50%       72.000000         9.000000     26.800000             65.000000\n",
      "75%       83.000000        14.000000     30.900000             82.000000\n",
      "max       94.000000        19.000000     35.000000             99.000000\n",
      "\n",
      "Shapes BEFORE train/test split:\n",
      "X shape: (74283, 23) y shape: (74283,)\n",
      "\n",
      "Shapes AFTER train/test split:\n",
      "X_train: (59426, 23) y_train: (59426,)\n",
      "X_test:  (14857, 23) y_test:  (14857,)\n",
      "\n",
      "Shapes AFTER Oversampling (train only):\n",
      "X_train_res: (69712, 23) y_train_res: (69712,)\n"
     ]
    }
   ],
   "source": [
    "# 2) EDA Prints\n",
    "print(\"\\n===== Basic Info =====\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n===== Value counts of Target =====\")\n",
    "print(df[TARGET_COL].value_counts())\n",
    "\n",
    "# Check numeric summary\n",
    "print(\"\\n===== Numeric Describe =====\")\n",
    "print(df.describe())\n",
    "\n",
    "# 3) Train/Test Split + Oversample\n",
    "# Drop 'Country'\n",
    "if \"Country\" in df.columns:\n",
    "    df = df.drop(columns=[\"Country\"])\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL], errors=\"ignore\")\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "print(\"\\nShapes BEFORE train/test split:\")\n",
    "print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\nShapes AFTER train/test split:\")\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_test: \", X_test.shape,  \"y_test: \", y_test.shape)\n",
    "\n",
    "# Use RandomOverSampler on the training set\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_res, y_train_res = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Reset index after oversampling\n",
    "X_train_res = X_train_res.reset_index(drop=True)\n",
    "y_train_res = y_train_res.reset_index(drop=True)\n",
    "\n",
    "print(\"\\nShapes AFTER Oversampling (train only):\")\n",
    "print(\"X_train_res:\", X_train_res.shape, \"y_train_res:\", y_train_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "575147a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "575147a8",
    "outputId": "3a70a158-4a98-455f-bca7-b3068885e88e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== One-Hot Encoding =====\n",
      "Categorical columns: ['Cholesterol Level', 'Smoking Status', 'Dietary Habits', 'Employment Status', 'Alcohol Consumption', 'Stress Levels', 'Physical Activity Level', 'Urban vs Rural Living', 'Marital Status', 'Depression Level', 'Diabetes', 'Sleep Quality', 'Income Level', 'Family History of Alzheimer’s', 'Social Engagement Level', 'Hypertension', 'Air Pollution Exposure', 'Gender', 'Genetic Risk Factor (APOE-ε4 allele)']\n",
      "\n",
      "Final training data shape: (69712, 35) (69712,)\n",
      "Final testing data shape:  (14857, 35) (14857,)\n",
      "\n",
      "X_train_res columns:\n",
      " Index(['Age', 'Education Level', 'BMI', 'Cognitive Test Score',\n",
      "       'Cholesterol Level_Normal', 'Smoking Status_Former',\n",
      "       'Smoking Status_Never', 'Dietary Habits_Healthy',\n",
      "       'Dietary Habits_Unhealthy', 'Employment Status_Retired',\n",
      "       'Employment Status_Unemployed', 'Alcohol Consumption_Occasionally',\n",
      "       'Alcohol Consumption_Regularly', 'Stress Levels_Low',\n",
      "       'Stress Levels_Medium', 'Physical Activity Level_Low',\n",
      "       'Physical Activity Level_Medium', 'Urban vs Rural Living_Urban',\n",
      "       'Marital Status_Single', 'Marital Status_Widowed',\n",
      "       'Depression Level_Low', 'Depression Level_Medium', 'Diabetes_Yes',\n",
      "       'Sleep Quality_Good', 'Sleep Quality_Poor', 'Income Level_Low',\n",
      "       'Income Level_Medium', 'Family History of Alzheimer’s_Yes',\n",
      "       'Social Engagement Level_Low', 'Social Engagement Level_Medium',\n",
      "       'Hypertension_Yes', 'Air Pollution Exposure_Low',\n",
      "       'Air Pollution Exposure_Medium', 'Gender_Male',\n",
      "       'Genetic Risk Factor (APOE-ε4 allele)_Yes'],\n",
      "      dtype='object')\n",
      "Number of columns =  35\n"
     ]
    }
   ],
   "source": [
    "# 4) Scaling & One-Hot Encoding\n",
    "numeric_cols = [\"Age\", \"Education Level\", \"BMI\", \"Cognitive Test Score\"]\n",
    "categorical_cols = list(set(X_train_res.columns) - set(numeric_cols))\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col not in X_train_res.columns:\n",
    "        print(f\"Warning: numeric column '{col}' not found in X_train_res columns\")\n",
    "\n",
    "# Scale numeric columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on train and transform\n",
    "X_train_res[numeric_cols] = scaler.fit_transform(X_train_res[numeric_cols])\n",
    "# Transform test\n",
    "if set(numeric_cols).issubset(X_test.columns):\n",
    "    X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "# One-Hot encode categorical columns\n",
    "print(\"\\n===== One-Hot Encoding =====\")\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "X_train_res = pd.get_dummies(X_train_res, columns=categorical_cols, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Ensure X_test has same columns as X_train_res\n",
    "X_test = X_test.reindex(columns=X_train_res.columns, fill_value=0)\n",
    "\n",
    "# Convert target to binary 0/1\n",
    "y_train_res_bin = (y_train_res == \"Yes\").astype(int)\n",
    "y_test_bin = (y_test == \"Yes\").astype(int)\n",
    "\n",
    "print(\"\\nFinal training data shape:\", X_train_res.shape, y_train_res_bin.shape)\n",
    "print(\"Final testing data shape: \", X_test.shape,  y_test_bin.shape)\n",
    "\n",
    "# Print columns for debug\n",
    "print(\"\\nX_train_res columns:\\n\", X_train_res.columns)\n",
    "print(\"Number of columns = \", len(X_train_res.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "932744b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "932744b6",
    "outputId": "39c54103-673b-4fb8-e13f-3a33cf5588ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting DataFrames to float32 ...\n",
      "Conversion done.\n",
      "Creating train_dataset ...\n",
      "Creating test_dataset ...\n",
      "Train dataset length: 69712\n",
      "Test dataset length: 14857\n",
      "\n",
      "Checking first 5 samples in dataset ...\n",
      "Index=0, features shape=torch.Size([35]), label=0.0\n",
      "Index=1, features shape=torch.Size([35]), label=1.0\n",
      "Index=2, features shape=torch.Size([35]), label=0.0\n",
      "Index=3, features shape=torch.Size([35]), label=1.0\n",
      "Index=4, features shape=torch.Size([35]), label=0.0\n"
     ]
    }
   ],
   "source": [
    "# 5) PyTorch Dataset & DataLoader\n",
    "# Convert all columns to float32\n",
    "print(\"\\nConverting DataFrames to float32 ...\")\n",
    "X_train_res = X_train_res.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "print(\"Conversion done.\")\n",
    "\n",
    "# Custom Dataset\n",
    "class BinaryDataset(Dataset):\n",
    "    \"\"\"Custom PyTorch Dataset for binary classification.\"\"\"\n",
    "    def __init__(self, data_df, labels):\n",
    "        # Convert DataFrame -> torch tensors\n",
    "        self.data = torch.tensor(data_df.values, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Create dataset\n",
    "print(\"Creating train_dataset ...\")\n",
    "train_dataset = BinaryDataset(X_train_res, y_train_res_bin)\n",
    "print(\"Creating test_dataset ...\")\n",
    "test_dataset  = BinaryDataset(X_test,      y_test_bin)\n",
    "\n",
    "print(\"Train dataset length:\", len(train_dataset))\n",
    "print(\"Test dataset length:\", len(test_dataset))\n",
    "\n",
    "# Iterate a few samples\n",
    "def manual_iteration_check(ds, n=5):\n",
    "    print(f\"\\nChecking first {n} samples in dataset ...\")\n",
    "    for i in range(n):\n",
    "        features, label = ds[i]\n",
    "        print(f\"Index={i}, features shape={features.shape}, label={label}\")\n",
    "\n",
    "manual_iteration_check(train_dataset, n=5)\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1a0dd3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1a0dd3c",
    "outputId": "58687989-96bb-4beb-97f9-f7d07d157e9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Architecture:\n",
      "SimpleMLP(\n",
      "  (fc1): Linear(in_features=35, out_features=16, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 6) Define a Simple MLP\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleMLP(input_size=X_train_res.shape[1]).to(device)\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee4cf4f0",
   "metadata": {
    "id": "ee4cf4f0"
   },
   "outputs": [],
   "source": [
    "# 7) Training Loop\n",
    "def train_model(model, train_loader, epochs=5, lr=0.001):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (xb, yb) in enumerate(train_loader):\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb).squeeze()\n",
    "            loss = loss_fn(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b59fc1fc",
   "metadata": {
    "id": "b59fc1fc"
   },
   "outputs": [],
   "source": [
    "# 8) Evaluation\n",
    "def evaluate_model(model, X_data, y_data, threshold=0.5):\n",
    "    model.eval()\n",
    "    inputs = torch.tensor(X_data.values, dtype=torch.float32).to(device)\n",
    "    labels = torch.tensor(y_data.values, dtype=torch.float32).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs).squeeze()\n",
    "        preds = (outputs >= threshold).float()\n",
    "\n",
    "    # Move back to CPU for scoring\n",
    "    preds_np = preds.cpu().numpy()\n",
    "    labels_np = labels.cpu().numpy()\n",
    "    acc = accuracy_score(labels_np, preds_np)\n",
    "    prec = precision_score(labels_np, preds_np, zero_division=0)\n",
    "    rec = recall_score(labels_np, preds_np, zero_division=0)\n",
    "    f1 = f1_score(labels_np, preds_np, zero_division=0)\n",
    "    auc = roc_auc_score(labels_np, outputs.cpu().numpy())\n",
    "\n",
    "    print(\"\\n--- Evaluation Results ---\")\n",
    "    print(f\"Accuracy:  {acc:.3f}\")\n",
    "    print(f\"Precision: {prec:.3f}\")\n",
    "    print(f\"Recall:    {rec:.3f}\")\n",
    "    print(f\"F1 Score:  {f1:.3f}\")\n",
    "    print(f\"AUC:       {auc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c487ecd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c487ecd8",
    "outputId": "b3195d32-b3c2-4ae9-b8c8-12855a795e8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Starting Training =====\n",
      "Epoch [1/100] - Loss: 0.5767\n",
      "Epoch [2/100] - Loss: 0.5602\n",
      "Epoch [3/100] - Loss: 0.5583\n",
      "Epoch [4/100] - Loss: 0.5579\n",
      "Epoch [5/100] - Loss: 0.5568\n",
      "Epoch [6/100] - Loss: 0.5560\n",
      "Epoch [7/100] - Loss: 0.5557\n",
      "Epoch [8/100] - Loss: 0.5554\n",
      "Epoch [9/100] - Loss: 0.5545\n",
      "Epoch [10/100] - Loss: 0.5537\n",
      "Epoch [11/100] - Loss: 0.5530\n",
      "Epoch [12/100] - Loss: 0.5525\n",
      "Epoch [13/100] - Loss: 0.5516\n",
      "Epoch [14/100] - Loss: 0.5510\n",
      "Epoch [15/100] - Loss: 0.5506\n",
      "Epoch [16/100] - Loss: 0.5501\n",
      "Epoch [17/100] - Loss: 0.5498\n",
      "Epoch [18/100] - Loss: 0.5496\n",
      "Epoch [19/100] - Loss: 0.5496\n",
      "Epoch [20/100] - Loss: 0.5492\n",
      "Epoch [21/100] - Loss: 0.5491\n",
      "Epoch [22/100] - Loss: 0.5488\n",
      "Epoch [23/100] - Loss: 0.5487\n",
      "Epoch [24/100] - Loss: 0.5485\n",
      "Epoch [25/100] - Loss: 0.5485\n",
      "Epoch [26/100] - Loss: 0.5483\n",
      "Epoch [27/100] - Loss: 0.5479\n",
      "Epoch [28/100] - Loss: 0.5482\n",
      "Epoch [29/100] - Loss: 0.5476\n",
      "Epoch [30/100] - Loss: 0.5478\n",
      "Epoch [31/100] - Loss: 0.5475\n",
      "Epoch [32/100] - Loss: 0.5474\n",
      "Epoch [33/100] - Loss: 0.5473\n",
      "Epoch [34/100] - Loss: 0.5474\n",
      "Epoch [35/100] - Loss: 0.5470\n",
      "Epoch [36/100] - Loss: 0.5473\n",
      "Epoch [37/100] - Loss: 0.5469\n",
      "Epoch [38/100] - Loss: 0.5468\n",
      "Epoch [39/100] - Loss: 0.5467\n",
      "Epoch [40/100] - Loss: 0.5466\n",
      "Epoch [41/100] - Loss: 0.5463\n",
      "Epoch [42/100] - Loss: 0.5462\n",
      "Epoch [43/100] - Loss: 0.5460\n",
      "Epoch [44/100] - Loss: 0.5459\n",
      "Epoch [45/100] - Loss: 0.5456\n",
      "Epoch [46/100] - Loss: 0.5458\n",
      "Epoch [47/100] - Loss: 0.5455\n",
      "Epoch [48/100] - Loss: 0.5453\n",
      "Epoch [49/100] - Loss: 0.5453\n",
      "Epoch [50/100] - Loss: 0.5452\n",
      "Epoch [51/100] - Loss: 0.5450\n",
      "Epoch [52/100] - Loss: 0.5448\n",
      "Epoch [53/100] - Loss: 0.5452\n",
      "Epoch [54/100] - Loss: 0.5448\n",
      "Epoch [55/100] - Loss: 0.5450\n",
      "Epoch [56/100] - Loss: 0.5445\n",
      "Epoch [57/100] - Loss: 0.5449\n",
      "Epoch [58/100] - Loss: 0.5447\n",
      "Epoch [59/100] - Loss: 0.5446\n",
      "Epoch [60/100] - Loss: 0.5444\n",
      "Epoch [61/100] - Loss: 0.5444\n",
      "Epoch [62/100] - Loss: 0.5443\n",
      "Epoch [63/100] - Loss: 0.5443\n",
      "Epoch [64/100] - Loss: 0.5441\n",
      "Epoch [65/100] - Loss: 0.5441\n",
      "Epoch [66/100] - Loss: 0.5440\n",
      "Epoch [67/100] - Loss: 0.5442\n",
      "Epoch [68/100] - Loss: 0.5440\n",
      "Epoch [69/100] - Loss: 0.5439\n",
      "Epoch [70/100] - Loss: 0.5440\n",
      "Epoch [71/100] - Loss: 0.5438\n",
      "Epoch [72/100] - Loss: 0.5439\n",
      "Epoch [73/100] - Loss: 0.5438\n",
      "Epoch [74/100] - Loss: 0.5435\n",
      "Epoch [75/100] - Loss: 0.5435\n",
      "Epoch [76/100] - Loss: 0.5438\n",
      "Epoch [77/100] - Loss: 0.5437\n",
      "Epoch [78/100] - Loss: 0.5436\n",
      "Epoch [79/100] - Loss: 0.5434\n",
      "Epoch [80/100] - Loss: 0.5432\n",
      "Epoch [81/100] - Loss: 0.5432\n",
      "Epoch [82/100] - Loss: 0.5432\n",
      "Epoch [83/100] - Loss: 0.5430\n",
      "Epoch [84/100] - Loss: 0.5434\n",
      "Epoch [85/100] - Loss: 0.5431\n",
      "Epoch [86/100] - Loss: 0.5431\n",
      "Epoch [87/100] - Loss: 0.5430\n",
      "Epoch [88/100] - Loss: 0.5432\n",
      "Epoch [89/100] - Loss: 0.5427\n",
      "Epoch [90/100] - Loss: 0.5432\n",
      "Epoch [91/100] - Loss: 0.5429\n",
      "Epoch [92/100] - Loss: 0.5429\n",
      "Epoch [93/100] - Loss: 0.5427\n",
      "Epoch [94/100] - Loss: 0.5427\n",
      "Epoch [95/100] - Loss: 0.5429\n",
      "Epoch [96/100] - Loss: 0.5426\n",
      "Epoch [97/100] - Loss: 0.5428\n",
      "Epoch [98/100] - Loss: 0.5428\n",
      "Epoch [99/100] - Loss: 0.5428\n",
      "Epoch [100/100] - Loss: 0.5424\n"
     ]
    }
   ],
   "source": [
    "# Train & Evaluate\n",
    "print(\"\\n===== Starting Training =====\")\n",
    "train_model(model, train_loader, epochs=100, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a12496ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a12496ad",
    "outputId": "8d8d79d2-0525-4e23-ec8c-2961949b2af8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Evaluating on Test Set =====\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Accuracy:  0.718\n",
      "Precision: 0.627\n",
      "Recall:    0.783\n",
      "F1 Score:  0.697\n",
      "AUC:       0.789\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Evaluating on Test Set =====\")\n",
    "evaluate_model(model, X_test, y_test_bin, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6dbe31",
   "metadata": {
    "id": "cf6dbe31"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
